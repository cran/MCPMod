%Rtex <- function(path, file){                            
%  setwd(path)                                            
%  pf <- paste(path, file, sep = "")                      
%  Sweave(pf)
%  substring(pf, nchar(pf)-3, nchar(pf)) <- ".tex"        
%  com <- paste("pdflatex ", pf, sep = "")                
%  system(com)                                            
%}                                                        
% Rtex("D:/Projekte/MCP-ModPackage/R-Code/Vignette/","MCPMod.Rnw") 

\documentclass[nojss]{jss}
\usepackage{amsmath} 
%% need no \usepackage{Sweave.sty} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\VignetteIndexEntry{Describes MCP-Mod methodology and gives an overview of the MCPMod R-package}
%\VignetteDepends{lattice,mvtnorm}
%\VignetteKeywords{clinical trial, dose-response, minimum effective dose, multiple contrast test, phase II trials}
%\VignettePackage{MCPMod}

\author{Bj{\"o}rn Bornkamp\\Technische Universit{\"a}t\\Dortmund 
\And Jos{\'e} Pinheiro\\Novartis Pharmaceuticals \And        
Frank Bretz\\Novartis Pharma AG}

\Plainauthor{Bj{\"o}rn Bornkamp, Jos{\'e} Pinheiro, Frank Bretz} 
\title{\pkg{MCPMod}: An \proglang{R} Package for the Design and 
Analysis of Dose-Finding Studies}

\Plaintitle{MCPMod: An R Package for the Design and Analysis of 
Dose-Finding Studies} \Shorttitle{MCPMod: An R Package for 
Dose-Finding Studies} 

\Abstract{ This vignette is an updated version of \cite{born:pinh:bret:2009}
  and describes the \pkg{MCPMod} package for the
  \proglang{R} programming environment. The package
  implements a methodology for the design and
  analysis of dose-response studies that combines aspects of multiple
  comparison procedures and modeling approaches
  \citep{bret:pinh:bran:2005}. The package provides tools
  for the analysis of dose finding trials, as well as a variety of
  tools necessary to plan an experiment to be analysed using the
  MCP-Mod methodology. } 
  
\Keywords{clinical trial, dose-response, minimum 
  effective dose, multiple contrast test, phase II trials} 

\Plainkeywords{clinical trial, dose-response, 
minimum effective dose, multiple contrast test, phase II trials}
 \SweaveOpts{keep.source=TRUE} 

\Address{
  Björn Bornkamp\\
  Fakultät Statistik\\
  Technische Universität Dortmund\\
  44221 Dortmund, Germany\\
  E-mail: \email{bornkamp@statistik.tu-dortmund.de}\\

  José Pinheiro\\
  Biostatistics Department\\
  Novartis Pharmaceuticals Corp.\\
  East Hanover, New Jersey 07936-1080, USA\\
  E-mail: \email{jose.pinheiro@novartis.com}\\

  Frank Bretz\\
  Biostatistics Department\\
  Novartis Pharma AG\\
  CH-4002 Basel, Switzerland\\
  E-mail: \email{frank.bretz@novartis.com}\\
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document} 
An earlier version of this vignette has been published by the 
Journal of Statistical Software:\\
Bornkamp B, Pinheiro JC, Bretz, F (2009): ``\pkg{MCPMod}: An 
\proglang{R} Package for the Design and Analysis of Dose-Finding 
Studies'', {\em Journal of Statistical Software}, \textbf{29}(7), 1--23.

\section{Introduction} \label{sec:intro} 

In pharmaceutical drug development, dose-response studies 
typically have two main goals. The first goal is to establish 
that changes in dose lead to desirable changes in the (efficacy 
and/or safety) endpoint(s) of interest, the so-called 
\emph{proof-of-concept} (PoC) step. Once such a dose-response 
signal has been shown, the second goal is then to select one or 
more ``good'' dose level(s) for the confirmatory Phase III 
studies, the so-called \emph{dose-finding} step.

Traditionally these goals have been addressed \emph{either} by 
using a multiple comparison procedure (MCP), \emph{or} by using a 
modeling (Mod) approach. The MCP approach regards the dose as a 
qualitative factor and generally makes few, if any, assumptions 
about the underlying dose-response relationship. However, 
inferences about the target dose are restricted to the discrete, 
possibly small, set of doses used in the trial. Within the 
modeling approach, a parametric (typically non-linear) functional 
relationship is assumed between dose and response. The dose is 
taken to be a quantitative factor, allowing greater flexibility 
for target dose estimation. The validity of the modeling 
approach, however, strongly depends on an appropriate 
dose-response model being pre-specified for the analysis.

In this paper we present the \pkg{MCPMod} package written in the 
\proglang{R} system for statistical computing \citep{R} and 
available from the Comprehensive \proglang{R} Archive Network at 
\url{http://CRAN.R-project.org/package=MCPMod}. The package 
implements a hybrid methodology, combining multiple comparison 
procedures with modeling techniques (called MCP-Mod procedure, 
\citep{bret:pinh:bran:2005}). This approach provides the 
flexibility of modeling for dose estimation, while preserving the 
robustness to model misspecification associated with MCP. Figure 
\ref{overview:MCPMod} gives an overview of the MCP-Mod 
procedure.  It starts by defining a set of \emph{candidate} 
models $\mathcal{M}$ covering a suitable range of dose-response 
shapes.  Each of the dose-response shapes in the candidate set is 
tested using appropriate contrasts and employing MCP techniques 
that preserve the family-wise error rate (FWER). PoC is 
established when at least one of the model tests is significant. 
Once PoC is verified, either a ``best'' model or a weighted 
average of the set of significant models $\mathcal{M}^* \subseteq 
\mathcal{M}$ is used to estimate the dose-response profile and 
the target doses of interest.

\vspace{1cm}

\begin{figure}[h!] \begin{center} \begin{picture}(200,110)
  \linethickness{1pt}
  \sf
 % put the frames for the individual steps; each of the 5 boxes embedded in a minipage
  \put(35,100){\framebox(133,13){
      \begin{minipage}[c][1cm][c]{10cm}
        \begin{center}
          Set of candidate models $\mathcal{M}$
        \end{center}
      \end{minipage}
      }}
  \put(28,75){\framebox(144,13){
      \begin{minipage}[c][1cm][c]{10cm}
        \begin{center}
          Optimum contrast coefficients
        \end{center}
      \end{minipage}
      }}
  \put(0,50){\framebox(200,13){
      \begin{minipage}[c][1cm][c]{10cm}
        \begin{center}
          Test for a significant dose-response signal
        \end{center}
      \end{minipage}
      }}
  \put(28,25){\framebox(135,13){
      \begin{minipage}[c][1cm][c]{10cm}
        \begin{center}
          Model selection or averaging
        \end{center}
      \end{minipage}
      }}
  \put(0,0){\framebox(200,13){
      \begin{minipage}[c][1cm][c]{10cm}
        \begin{center}
          Dose-response and target dose estimation
        \end{center}
      \end{minipage}
      }}
                            %put the arrows to connect the frames
  \linethickness{0.4pt}
  \put(66.6,99){\vector(0,-10){10}}
  \put(66.6,74){\vector(0,-10){10}}
  \put(66.6,49){\vector(0,-10){10}}
  \put(66.6,24){\vector(0,-10){10}}
  \put(133.3,99){\vector(0,-10){10}}
  \put(133.3,74){\vector(0,-10){10}}
  \put(133.3,49){\vector(0,-10){10}}
  \put(133.3,24){\vector(0,-10){10}}
\end{picture} \end{center} \label{overview:MCPMod} 
\caption{Schematic overview of the MCP-Mod procedure} \end{figure}


As outlined above, the MCP-Mod procedure is performed in several 
steps: 1) calculation of contrast coefficients, representing the 
candidate model shapes, 2) conduct of a multiple contrast test, 
and, depending on the result, 3) a model selection step to fit 
(typically non-linear) dose-response models and to estimate the 
target doses. Each individual step above can be implemented with 
the \proglang{R} statistical language, possibly using add-on 
packages available at the CRAN servers 
(\url{http://CRAN.R-project.org/}). However, it is desirable to 
have one package, which performs these steps automatically and 
also allows to design a trial for the MCP-Mod procedure. The 
\pkg{MCPMod} package provides these functionalities and the aim 
of this paper is to give a detailed description of the package.

For self containment of the paper we will first review the key
features and statistical methods of the MCP-Mod procedure in
Section~\ref{sec:mcpmod}, while the \pkg{MCPMod} package will be
introduced and illustrated with examples in Section~\ref{sec:pkge}.

\section{MCP-Mod: Combining multiple comparisons and modeling}
\label{sec:mcpmod}

\subsection{Notation} Assume that we observe a response $Y$ for a
given set of parallel groups of patients corresponding to doses $d_2,
d_3, \ldots, d_k$ plus placebo $d_1$, for a total of $k$ arms. For the
purpose of testing PoC and estimating target doses, we consider the
one-way layout

\begin{equation}
  \label{eq:baseModel}
  Y_{ij} =  \mu_{d_i} +
  \epsilon_{ij}, \quad \epsilon_{ij}
  \,\sim\, \mathcal{N}
  (0,\sigma^2),\;
  i=1,\ldots,k, j=1,\ldots,n_i,
\end{equation}

where $\mu_{d_i} = f(d_i,\mbox{\boldmath$\theta$})$ denotes the
mean response at dose $d_i$ for some dose-response model
$f(d,\mbox{\boldmath$\theta$})$, $n_i$ denotes the number of
patients allocated to dose $d_i$, $N=\sum_{i=1}^k n_i$ is the
total sample size, and $\epsilon_{ij}$ denotes the error term for
patient $j$ within dose group $i$.
Following~\cite{bret:pinh:bran:2005}, we note that most
parametric dose-response models $f(d, \mbox{\boldmath$\theta$})$
used in practice can be written as

\begin{equation}
  \label{eq:drModel}
  f(d, \mbox{\boldmath$\theta$}) = \theta_0 + \theta_1 f^0(d, \mbox{\boldmath$\theta$}^*),
\end{equation}

where $f^0(d, \mbox{\boldmath$\theta$}^*)$ denotes the standardized
model function, parameterized by the vector
$\mbox{\boldmath$\theta$}^*$. In this parameterization, $\theta_0$ is
a location and $\theta_1$ a scale parameter such that only the
parameter-vector $\mbox{\boldmath$\theta$}^*$ determines the shape of
the model function. As seen later, it is sufficient to consider the
standardized model $f^0$ instead of the full model $f$ for the
derivation of the optimal model contrasts.

\subsection{MCP-Mod methodology} \label{sec:mcpmodmeth} In this
subsection we review the core elements of the MCP-Mod methodology. We
start considering the basic MCP-Mod procedure for the analysis of a
dose-response trial and then focus on design issues. For more
information on the basic methodology see \cite{bret:pinh:bran:2005},
for recommendations regarding the practical implementation and design
aspects see \cite{pinh:born:bret:2006}.

\subsubsection{Analysis considerations}

The motivation for MCP-Mod is based on the work by
\cite{tuke:cimi:heys:1985}, who recognized that the power of standard
dose-response trend tests depends on the (unknown) dose-response
relationship. They proposed to simultaneously use several trend tests
and subsequently to adjust the resulting $p-$values for
multiplicity. \cite{bret:pinh:bran:2005} formalized this approach and
extended it in several ways.

Assume that a set $\mathcal{M}$ of $M$ parameterized candidate models
is given, with corresponding model functions $f_m(d,
\mbox{\boldmath$\theta$}_m), m=1, \ldots, M,$ and parameters
$\mbox{\boldmath$\theta$}^*_m$ of the standardized models $f^0_m$
(determining the model shapes). For each of the dose-response models
in the candidate set we would like to test the hypothesis $H_0^m$:
$\mathbf{c}_m'\boldsymbol{\mu} = 0$, where $\mathbf{c}_m=(c_{m1},
\ldots, c_{mk})^\prime$ is the optimal contrast vector representing
model $m$, subject to $\sum_{i=1}^{k} c_{mi}=0$. Each of the
dose-response models in the candidate set is hence tested using a
single contrast test,

$$ T_m=\frac{\sum_{i=1}^k c_{mi}\bar{Y}_i}{S\sqrt{\sum_{i=1}^k
c_{mi}^2/n_i}}, \quad m=1, \ldots ,M, $$

where $S^2 = \sum_{i=1}^k \sum_{j=1}^{n_i} (Y_{ij} - \bar{Y}_i)^2
/ (N - k)$ is the pooled variance estimate. Every single contrast
test thus translates into a decision procedure to determine
whether the given dose-response shape is statistically
significant, based on the observed data.

The contrast coefficients $c_{m1}, \ldots, c_{mk}$ for the $m$-th
model are chosen such that they maximize the power to detect the
underlying model. It can be shown that these optimal contrast
coefficients do not depend on the full parameter vector
$\boldsymbol{\theta}_m$ of the model, but only the parameters in its
standardized model function $\boldsymbol{\theta}_m^*$, which determine
the model shape (see \cite{bret:pinh:bran:2005}) and the group sample
sizes.  Letting $(\mu^0_{m1},\ldots,\mu^0_{mk})'=(f_m^0(d_1,
\mbox{\boldmath$\theta$}_m^*),\ldots,f_m^0(d_k,
\mbox{\boldmath$\theta$}_m^*))'$, the \textit{i}th entry of the
optimal contrast $\mathbf{c}_m$ for detecting the shape $m$ is
proportional to

\begin{equation}
\label{eq:optcont}
n_i(\mu^0_{mi}-\bar{\mu}), \; i=1,\ldots,k,
\end{equation}

where $\bar{\mu}=N^{-1}\sum_{i=1}^k \mu^0_{mi} n_i$
(\cite{born:2006} p. 88, \cite{case:berg:1990} p. 519). A unique
representation of the optimal contrast can be obtained by
imposing the regularity condition $\sum_{i=1}^k c_{mi}^2 = 1$.

The final detection of a significant dose-response signal
(\emph{i.e.}, demonstrating PoC), is based on the maximum
contrast test statistic

$$ T_{\max} = \max \{ T_1, \ldots, T_M\}.$$

Under the null hypothesis of no dose-response effect
$\mu_{d_1}=...=\mu_{d_k}$ and under the distributional assumptions
stated in equation~(\ref{eq:baseModel}), $T_1,\ldots,T_M$ jointly
follow a central multivariate $t$ distribution with $N-k$ degrees of
freedom and correlation matrix $\mbox{\boldmath$R$}=(\rho_{ij})$,
where

\begin{equation}
\label{eq:contcorr}
\rho_{ij} =
\frac{\sum_{l=1}^k c_{il}c_{jl}/n_l}{\sqrt{\sum_{l=1}^k c_{il}^2 /
n_l \sum_{l=1}^k c_{jl}^2 / n_l}}.
\end{equation}

Multiplicity adjusted critical values and $p-$values can be calculated
using the identity of the sets $[T_{\max}\leq q]=[T_1\leq
  q,\ldots,T_M\leq q],$ where $q$ is a real number. As the joint
distribution of $(T_1,\ldots,T_M)'$ is multivariate $t$,
numerical integration routines for evaluation of multivariate $t$
integrals, such as the randomized quasi-Monte Carlo methods of
\citet{genz:bret:2002} implemented in the \proglang{R} package
\pkg{mvtnorm} \citep{genz:bret:hoth:2008}, can be used to compute
the desired equicoordinate quantiles of the multivariate $t$
distribution. PoC is hence established if $T_{\max} \geq
q_{1-\alpha}$, where $q_{1-\alpha}$ is the multiplicity adjusted
critical value at level $1-\alpha$ (\textit{i.e}., the
equicoordinate $1-\alpha$ quantile of the corresponding central
multivariate t distribution). Furthermore, all dose-response
shapes with contrast test statistics larger than $q_{1-\alpha}$
can be declared statistically significant at level $1-\alpha$
under strong control of the FWER. These models then form a
reference set $\mathcal{M}^*=\{M_1, \ldots, M_L\}\subseteq
\mathcal{M}$ of $L$ significant models. If no candidate model is
statistically significant, the procedure stops indicating that a
dose-response relationship can not be established from the
observed data (\emph{i.e.}, no PoC).

If PoC has been established, the next step is to estimate the 
dose-response curve and the target doses of interest. This can be 
achieved either by selecting a single model out of $\mathcal{M}^*$ 
or by applying model averaging techniques to $\mathcal{M}^*$. 
There are different possibilities to select a single dose-response 
model out of $\mathcal{M}^*$ for target dose estimation. One can 
base the choice, for example, on the contrast test statistics, 
\textit{i.e.} selecting the model corresponding to the maximum 
contrast test statistic. Standard information criteria like the 
$AIC$ or $BIC$ might also be used. The estimate of the model 
function is then obtained by calculating the least squares 
estimates for \mbox{\boldmath$\theta$}. For non-linear models 
iterative optimization techniques need to be used, such as those 
implemented in the \code{nls} function in \proglang{R}. As the 
non-linear models described here are partially linear (see 
equation (\ref{eq:drModel})), this can be exploited in the 
\code{nls} function by using the Golub-Pereyra algorithm (see 
\citet{golu:pere:2003} for a review of these methods). So we only 
need to derive starting values for the standardized model 
parameters \mbox{\boldmath$\theta^*$}. Although we use automatic 
methods for finding good data-based starting values for 
\mbox{\boldmath$\theta^*$}, convergence problems can occur, 
especially when the number of dose levels used in the trial is 
small compared to the parameters in the model function. In the 
case of non-convergence the `best' of the remaining significant, 
converging models can be used for dose estimation, if any. An 
approach to partially overcome these convergence issues is to use 
box constraints on \mbox{\boldmath$\theta^*$}. This will be 
implemented as an alternative in future versions of the package.

Once a dose-response model has been selected, one can proceed to
estimate the target dose(s) of interest. One possible choice is the
minimum effective dose ($MED$), which is defined as the smallest dose
ensuring a clinically relevant and statistically significant
improvement over placebo \citep{rube:1995a}.  Formally, $$ MED =
\min\{d\in(d_1,d_k]: f(d)>f(d_1)+\Delta\}, $$ where $\Delta$ is the
  clinical relevance threshold. A common estimate for the $MED$ is

$$ \widehat{MED}=\min\{d\in(d_1,d_k]:
\hat{f}(d)>\hat{f}(d_1)+\Delta,L(d) > \hat{f}(d_1) \} $$

where $\hat{f}(d)$ is the predicted mean response at dose $d$, 
and $L(d)$ is the corresponding lower bound of the pointwise 
confidence intervals of level $1-2\gamma$. Note that 
$\widehat{MED}$ corresponds to the $\widehat{MED}_2$ estimator in 
\cite{bret:pinh:bran:2005}, who found this estimator to be least 
biased compared to two other alternative estimates in a 
simulation study. A different target dose is the $EDp$ which is 
defined as the smallest dose that gives a certain percentage $p$ 
of the maximum effect $\delta_{\max}$ observed in $(d_1,d_k]$. 
Formally,

\begin{equation} \label{eq:EDp} EDp = \min\{d\in(d_1,d_k]:
f(d)>f(d_1)+p\delta_{\max} \},
\end{equation}

where $\delta_{\max}=f_{max}-f(d_1)$, and
$f_{\max}=\underset{d\in(d_1,d_k]}{\mathrm{max}}f(d)$. An estimate
  $\widehat{EDp}$ is obtained by plugging the empirical estimates into
  the definition (\ref{eq:EDp}).

An alternative to selecting a single dose-response model is to apply
model averaging techniques and produce weighted estimates across all
models in $\mathcal{M}^*$ for a given quantity $\boldsymbol{\psi}$ of
interest. In the context of dose-response analysis, the parameter
$\boldsymbol{\psi}$ could for example be a target dose ($MED, EDp,
\ldots$) or the mean responses at a specific dose
$d\in[d_1,d_k]$. \cite{buck:burn:augu:1997} proposed to use the
weighted estimate

\begin{equation*}
    \widehat{\boldsymbol{\psi}} = \sum_\ell w_\ell \widehat{\boldsymbol{\psi}}_\ell,
\end{equation*}

where $\widehat{\boldsymbol{\psi}}_\ell $ is the estimate of
$\boldsymbol{\psi} $ under model $\ell$ for given weights
$w_\ell$. The idea is thus to use estimates for the final data
analysis which rely on the averaged estimates across all $L$
models. \cite{buck:burn:augu:1997} proposed the use of the weights

\begin{equation}
    \label{eq:buckland}
    w_\ell = \frac{ p_\ell e^{ -\frac{IC_\ell}{2} } } { \sum_{j=1}^L p_\ell e^{
    -\frac{IC_j}{2} }  }, \quad \ell=1, \ldots, L,
\end{equation}

which are defined in dependence of a common information criterion
$IC$, such as $AIC$ or $BIC$ applied to each of the $L$ models, and
prior model weights $p_\ell$. If each model is given the same prior
model weight, the $p_\ell$ cancel out in equation (\ref{eq:buckland}).

\subsubsection{Design considerations I: Power and sample size
calculations}

An important step at the planning phase of any clinical trial is to
properly design the study in order to achieve the study
objectives. Because dose finding studies have two major goals, PoC
testing and dose estimation, different criteria can be used to design
a study. \cite{dett:bret:pepe:pinh:2008} derived optimal designs,
which minimize the (asymptotic) variance of the $MED$ estimate. Using
their approach, asymptotic confidence intervals for the $MED$ can be
calculated, conditional on a selected model. At the planning stage one
would then specify the maximum width of the confidence interval and
calculate the sample size necessary to ensure a certain precision of
the $MED$ estimate.

An alternative approach is to focus on calculating the sample size
necessary to achieve a pre-specified power to detect PoC
\citep{pinh:born:bret:2006}. We thus start by introducing the power
calculation under a given specific model $m$ from the candidate set
$\mathcal{M}$, generalize it afterwards to multiple models and finally
focus on sample size calculation.

The power of the MCP procedure is determined by the distribution of
$T_{\max}$ under the alternative hypothesis that the $m$-th
dose-response model is true. Under this assumption, the mean responses
at the doses $d_1, \ldots, d_k$ are $\mbox{\boldmath$\mu$}_m =
(f_m(d_1,\mbox{\boldmath$\theta$}_m),\ldots,f_m(d_k,\mbox{\boldmath$\theta$}_m))^{\prime}.$
The power to detect a dose-response signal (\textit{i.e.}, PoC) under
model $m$ for sample sizes
$\mbox{\boldmath$n$}=(n_1,\ldots,n_k)^{\prime}$ is then
\begin{equation}
  \label{eq:power}
  P(\max_l T_l \geq q_{1-\alpha} |\mbox{\boldmath$\mu$}=\mbox{\boldmath$\mu$}_m)
  = 1-P(T_1 < q_{1-\alpha},\ldots,T_M < q_{1-\alpha}|\mbox{\boldmath$\mu$}=\mbox{\boldmath$\mu$}_m).
\end{equation} It follows from the properties of the multivariate
$t$ distribution and the assumptions in
equation~(\ref{eq:baseModel}), that, under the  $m$-th model, the
contrast test statistics $T_1,\ldots,T_M$ are jointly distributed
as non-central multivariate $t$ with $N-k$ degrees of freedom and
correlation matrix $\mbox{\boldmath$R$}=(\rho_{ij})$. The
non-centrality parameter vector is $\mbox{\boldmath$\delta$}_m =
(\delta_{m1}, \ldots, \delta_{mM})^{\prime}$, where

$$\delta_{ml} =\frac{\sum_{i=1}^k
c_{li}\mu_{mi}}{\sigma\sqrt{\sum_{i=1}^k c_{li}^2/n_i}}, \; l =
1,\ldots,M.$$

Again, the \pkg{mvtnorm} package can be used to calculate the
necessary probabilities.

So far we have only considered the power calculation under a
single model $m$. In practice we would rather account for the
inherent model uncertainty. To this end, we would calculate the
power for each of the $M$ models from the candidate set
$\mathcal{M}$ and aggregate the resulting values into a single
\emph{combined} measure of power, such as the (weighted) average,
the minimum or a quantile. The sample size is then calculated as
the smallest sample size ensuring a minimum \emph{combined}
\emph{power} value, say $\pi^*$, to detect PoC under the assumed
set of dose-response mean vectors. We restrict ourselves to the
case that either the allocation weights $r_i \geq 0$, subject to
$\sum_i r_i=1$ or the allocation ratios $\rho_i$ relative to the
dose group with the fewest patients, \textit{i.e.}
$\rho_i=r_i/\min(r_i)$ are prespecified. The group sample sizes
$\mbox{\boldmath$n$} = (n_1,\ldots,n_k)$ can then be obtained
from $n_i = Nr_i$ for allocation weights or from $n_i =
\rho_in_{min}$, where $n_{min}$ is the smallest group sample
size. Since the combined power is a monotone increasing function
of $N$ (or $n_{min}$, if allocation ratios are specified) a
unique smallest integer giving a power larger than $\pi^*$ exists
(see also \cite{pinh:born:bret:2006}). The bisection search
method can be used to obtain the sample size ensuring a
pre-specified combined power $\pi^*$. In practice, rounding
techniques need to be applied to obtain integer sample sizes.

\subsubsection{Design considerations II: Sensitivity analysis}

In the derivations above we conditioned on the mean vectors
$\boldsymbol{\mu}_m$ in equation~(\ref{eq:power}) and hence on
the parameters
$\boldsymbol{\theta}_m=(\theta_{m0},\theta_{m1},\boldsymbol{\theta}^*_m)'$.
Since the sample size is calculated under this condition, it is
critical that the model parameters are reliably determined. For
the determination of location and scale parameters $\theta_{m0}$
and $\theta_{m1}$, prior knowledge about the expected placebo
response $\delta_0$ and the maximum response $\delta_{\max}$ can
be used at the design stage. It is typically straightforward to
plug in these quantities into the model equations, assuming that
$\boldsymbol{\theta}^*_m$ is known and then solving for
$\theta_{m0}$ and $\theta_{m1}$, see \cite{pinh:born:bret:2006}
for a more detailed description of this approach.

Based on prior knowledge about the shape of the model function,
\cite{pinh:bret:bran:2006} discussed strategies to obtain
guesstimates for the standardized model parameters
$\boldsymbol{\theta}^*_m$. The elicitation of prior information
for $\boldsymbol{\theta}^*_m$ may impact both the design
\textit{and} the analysis of a dose finding study using the
MCP-Mod methodology, as the guesstimates are used to obtain the
optimal model contrasts at the MCP step, which in turn determine
the effective power to detect PoC. Therefore, it is of importance
to investigate the sensitivity of the procedure to
misspecification of the parameters in the standardized models
and, in particular, the impact it has on the effective power to
detect PoC. \cite{pinh:born:bret:2006} considered different
measures of loss in power associated with a misspecification of
the standardized model parameters. One possibility, subsequently
denoted as $LP_1$, is to calculate the difference between the
nominal power (the power obtained, when the guesstimate is
correct) and the actual power (the power obtained, when the used
guesstimate does not coincide with the true parameter),
\textit{i.e.}

\begin{equation}
 \label{eq:lp1}
  LP_1 = \mathrm{nominal}\,\mathrm{power} -
\mathrm{actual}\,\mathrm{power}.
\end{equation}


Thus, $LP_1$ can be interpreted as the difference between the
power that was intended for the study and the power one actually
obtains. Alternatively, one could also calculate the difference
between the power that could be achieved if the true parameter
values were known at the design stage (potential power) and the
actual power. This is denoted by $LP_2$ and hence

$$LP_2 = \mathrm{potential}\,\mathrm{power} - \mathrm{actual}\,
\mathrm{power}.$$

Graphical methods can be used to display the loss in power for a range
of true standardized model parameters. From our experience the loss in
power associated with misspecification of the parameters in the
standardized model function is often negligible for reasonable
candidate sets, because dose-response models with parameter vectors
$\boldsymbol{\theta}_m$ deviating from the guesstimate
$\boldsymbol{\theta}_m^*$ are often detected from some other model in
the candidate set. In cases where the loss in power is not acceptable,
the inclusion of an additional model in the candidate set could be
considered.
\newpage
\section{The MCPMod package} \label{sec:pkge} \begin{figure}
  \unitlength 0.5cm
  \begin{center}
    \begin{picture}(20,11.5)
      \linethickness{1.1pt}
      \thicklines
      \put(5.5,11){\framebox(9,1){
          \begin{minipage}[c][1.cm][c]{10cm}
            \begin{center}
              \pkg{MCPMod}-Package
            \end{center}
          \end{minipage}
          }}
      \put(-4,8.5){\framebox(13,1){
          \begin{minipage}[c][1.cm][c]{10cm}
            \begin{center}
              Planning Code
            \end{center}
          \end{minipage}
          }}

      \put(11,8.5){\framebox(13,1){
          \begin{minipage}[c][1.cm][c]{10cm}
            \begin{center}
              Analysis Code
            \end{center}
          \end{minipage}
          }}
      \put(-4,-1){\framebox(14,8){
          \begin{minipage}[c][1.cm][c]{10cm}
            \begin{center}
              \texttt{guesst} - derivation of guesstimates\\
              \texttt{fullMod} - full models specification\\
              \texttt{plotModels} - model plots\\
              \code{planMM} - calculation of contrasts\\
              \hspace{1cm} and critical value\\
              \texttt{powerMM} - power calculations\\
              \texttt{sampSize} - sample size calcualtion\\
              \texttt{LP}- sensitivity analysis\\
            \end{center}
          \end{minipage}
          }}
            \put(11,-1){\framebox(14,8){
          \begin{minipage}[c][1.cm][c]{10cm}
            \begin{center}
              \texttt{MCPMod}\\
              multiple contrast test\\
              model selection/model averaging\\
              dose-response estimation \\
              target dose estimation\\
            \end{center}
          \end{minipage}
          }}
      \thicklines
      \put(5.495,10.95){\line(-1,-1){1.414}}
      \put(2.5,8.5){\line(0,-1){1.5}}
      \put(14.495,10.95){\line(1,-1){1.414}}
      \put(17.5,8.5){\line(0,-1){1.5}}
\end{picture} \end{center} \caption{Overview of main functions in
the \pkg{MCPMod} package.} \label{fig:overpkg} \end{figure}

In this section we describe the \proglang{R} package \pkg{MCPMod} for
implementing the MCP-Mod methodology. The package consists of two main
parts (see also Figure~\ref{fig:overpkg}). The first part contains
several functions that are useful for planning a trial: calculation of
the optimal contrasts and the critical value (\code{planMM}), the
sample size (\code{sampSize}) or functions that support the selection
of a `good' candidate set and sensitivity analysis (\code{guesst},
\code{plotModels}, \code{powerMM}, \code{LP}). The second part
consists of one main function named \code{MCPMod} that implements the
full MCP-Mod approach for analysis of a given dose-response data set.

\subsection{Preliminaries}

Before illustrating the different functions in more detail we
first describe how to specify the candidate set of models
$\mathcal{M}$ for these functions. Table \ref{tbl:models} gives
an overview of the dose-response models that are implemented
(note that user-defined non-linear models can also be specified,
see the package documentation for details). The candidate set of
models needs to be specified as a \code{list}, where the list
elements should be named according to the underlying
dose-response model function (see Table \ref{tbl:models}) and the
individual list entries should correspond to the required
guesstimates or \code{NULL} if no guesstimates are needed.
Suppose, for example, we want to include in our candidate set a
linear model, an E$_{\max}$ model and a logistic model. From the
standardized model functions in Table \ref{tbl:models} we see
that we need to specify one guesstimate for the E$_{\max}$ model
($ED_{50}$ parameter), two guesstimates for the logistic model
($ED_{50}$ and $\delta$) and none for the linear model (since its
standardized model function does not contain any unknown
parameters). Suppose our guesstimate for the $ED_{50}$ parameter
of the E$_{\max}$ model is $0.2$, while the guesstimate for
$(ED_{50}, \delta)'$ for the logistic model is $(0.25,0.09)'$. We
then specify the list

<<results=hide, echo=false>>= 
#options(width = 65)
library(MCPMod) 
@

<<results=hide>>= 
mods1 <- list(linear = NULL, emax = 0.2, logistic = c(0.25, 0.09)) 
@ 

In some cases one might want to include several model shapes per
model class. For example, if the candidate model set includes two
E$_{\max}$ model shapes, two logistic model shapes, a beta model
shape and a linear model shape the model list would look like

<<results=hide>>=
 mods2 <- list(linear = NULL, emax = c(0.05, 0.2), betaMod = c(0.5, 1),
             logistic = matrix(c(0.25, 0.7, 0.09, 0.06), byrow = FALSE,
             nrow = 2))
@

Thus, if multiple model shapes from the same model class are to 
be used, the parameters are handed over as a matrix, for models 
having two parameters in the standardized model function, and as 
a vector for one-parameter standardized models. This general 
structure applies to all built-in models. Note that the 
linear-in-log and the beta models also contain a parameter ($c$ 
and $D$, respectively, see Table \ref{tbl:models}) that is not 
estimated from the data but needs to be pre-specified. These 
parameters are not handed over via the candidate model list but 
via seperate arguments \code{scal} (corresponding to $D$) and 
\code{off} (corresponding to $c$) respectively to the top-level 
functions. 

 \begin{table}
  \begin{center}
  {\footnotesize
    \begin{tabular}{l|l|l|l|l}
    \multicolumn{1}{c|}{Name} & \multicolumn{1}{c|}{$f(d,\boldsymbol{\theta})$} & \multicolumn{1}{c|}{$f^0(d,\boldsymbol{\theta^*})$} & \multicolumn{1}{c|}{(*)} & \multicolumn{1}{c}{($\sharp$)} \\ \hline
      \code{linear}    & $E_0 + \delta d$ & $d$ & & \\
      \code{linlog}    & $E_0 + \delta \log(d + c)$ & $\log(d + c)$  & & $c$\\
      \code{quadratic} & $E_0 + \beta_1 d + \beta_2 d^2$ & $d + \delta d^2$$\,\mathrm{if}\,\beta_2<0$  & $\delta$ & \\
      \code{emax}      & $E_0+E_{\max} d/(ED_{50} + d)$ & $d/(ED_{50} + d)$ & $ED_{50}$ & \\
      \code{logistic}  & $E_0 + E_{\max}/\left\{1 + \exp\left[ \left(ED_{50} - d
  \right)/\delta \right] \right\}$ & $1/\left\{1 + \exp\left[ \left(ED_{50} - d
  \right)/\delta \right] \right\}$ & $(ED_{50}, \delta)'$ & \\
      \code{exponential} & $E_0 + E_1 (\exp(d/\delta) - 1)$ & $\exp(d/\delta) - 1$ & $\delta$ & \\
      \code{sigEmax}   & $E_0 + E_{\max} d^h/(ED_{50}^h + d^h)$ & $d^h/(ED_{50}^h + d^h)$ & $(ED_{50},h)'$ & \\
      \code{betaMod}   & $E_0 + E_{\max}B({\delta_1},{\delta_2}) (d/D)^{\delta_1}(1-d/D)^{\delta_2}$
       & $B({\delta_1},{\delta_2}) (d/D)^{\delta_1}(1-d/D)^{\delta_2}$ & $(\delta_1,\delta_2)'$ & $D$ \\ \hline
    \end{tabular}
    }
  \end{center}
  \caption{Dose-response models implemented in the \pkg{MCPMod} package. Column (*) lists for each model the
  parameters for which guesstimates are required and the order in which they need to be specified in the \texttt{models}
  list, while column ($\sharp$) lists the parameters, which fixed and not estimated. For the beta model  $B({\delta_1},{\delta_2}) =
({\delta_1}+{\delta_2})^{{\delta_1}+{\delta_2}}/({\delta_1}^{\delta_1}{\delta_2}^{\delta_2})$ 
and for the quadratic model $\delta=\frac{\beta_2}{|\beta_1|}$. 
For the quadratic model the standardized model function is given 
for the concave-shaped form. }
  \label{tbl:models}
\end{table}

\subsection{Planning Code} In this section we provide a brief
overview of the functions \code{guesst}, \code{plotModels},
\code{fullMod}, \code{planMM}, \code{powerMM}, \code{sampSize}
and \code{LP}. These functions are useful for designing a trial
using MCP-Mod. For a detailed description of the arguments to the
functions we refer to the documentation of the package.

\subsubsection[Function guesst]{Function \code{guesst}} The 
selection of suitable guesstimates and model shapes is a major 
aspect of the MCP-Mod methodology. Incorporating contrasts/models 
that are likely to be true (and excluding those that are very 
unlikely) can greatly improve the power of the methodology. The 
\code{guesst} function supports the translation of clinical 
knowledge available prior to the start of a study into the 
required guesstimates. The function calculates the guesstimates 
according to the percentage $p^*$ of the maximum effect that is 
achieved at a certain dose $d^*$.  Suppose, for example, we want 
to calculate a guesstimate for the $ED_{50}$ parameter from the 
E$_{\max}$ model. If we expect a response of 90\% at dose $0.2$, 
the $ED_{50}$ guesstimate can be calculated by calling

<<>>=
guesst(d = 0.2, p = 0.9, model = "emax")
@

With this guesstimate, the standardized model for the $E_{\max}$
model is given by $\displaystyle f^0(d,ED_{50})=d/(0.022222+d)$,
and the optimal contrast can be calculated from
equation~(\ref{eq:optcont}). For models with two standardized
model parameter one $(d^*,p^*)$ pair is not sufficient to obtain
guesstimates for the standardized model parameters. For example,
for the logistic model we need to specify two pairs to obtain a
guesstimate

<<>>=
guesst(d = c(0.05, 0.2), p = c(0.2, 0.9), model = "logistic")
@

In this example the standardized model function for the logistic
model is given by $\displaystyle f^0(d,ED_{50},\delta)=1/\{1 + 
\exp[ ( 0.1080279 - d ) / 0.0418583 ] \}$, from which the 
corresponding optimal contrast can be obtained. In a similar way 
one can obtain guesstimates with the \code{guesst} function for 
all built-in models.

\subsubsection[Function plotModels]{Function \code{plotModels}} 
Before deciding for any particular candidate set of model shapes 
it is useful to display them graphically. This can be done with 
the \code{plotModels} function. Since the model shapes, specified 
in the models list, do not depend on the location (defined 
through the baseline effect) and scale (defined through the 
maximum effect) of the model, one additionally needs to specify 
those via the \code{base} and \code{maxEff} arguments. Using the 
candidate set \code{mods2} defined above (and setting the 
\code{scal} parameter of the beta model equal to $1.2$), a 
graphical representation can be obtained as follows (see Figure 
\ref{fig:plotModels} for the output) 

<<results = hide>>= 
doses <- c(0, 0.05, 0.2, 0.6, 1) 
plotModels(mods2, doses, base = 0, maxEff = 0.4, scal = 1.2)
@
\begin{figure}[h!]
 \centering
<<fig=true, width=10, height=7, echo = false>>=
print(plotModels(mods2, doses, base = 0, maxEff = 0.4, scal = 1.2))
@
 \caption{Model shapes for the selected candidate model set, produced with \code{plotModels} function.}
 \label{fig:plotModels}
\end{figure}
                        
\subsubsection[Function fullMod]{Function \code{fullMod}} Similar 
to the \code{plotModels} function above, also other functions 
(\code{powerMM}, \code{sampSize}, \code{LP}) require information 
about the doses, the full model functions, \textit{i.e.} the 
candidate model shapes, the baseline effect, the maximum effect 
and possible other additional parameters like \code{off} or 
\code{scal}. The \code{fullMod} function derives the full model 
functions (\textit{i.e.} the location and scale parameters) for 
each model from the stated information (see Section 
\ref{sec:mcpmodmeth}) and packages this with the used dose levels 
into a \code{fullMod} object, which can then be used as an input 
parameter for the four above mentioned functions. When assuming 
the baseline effect 0 and the maximum effect 0.4 and using the 
candidate set \code{mods2} (and setting the \code{scal} parameter 
of the beta model equal to 1.2) one can package this information 
via

<<results=hide>>=
doses <- c(0, 0.05, 0.2, 0.6, 1)
fmods2 <- fullMod(mods2, doses, base = 0, maxEff = 0.4, scal = 1.2)        
@

\subsubsection[Function planMM]{Function \code{planMM}}

The \code{planMM} function calculates the quantities necessary to
conduct the multiple contrast test: The optimal model contrasts and
their correlations (see equations~(\ref{eq:optcont}) and
(\ref{eq:contcorr})) and the critical value using the \pkg{mvtnorm}
package. This information is returned in a \code{planMM} object. The
arguments \code{alpha} and \code{twoSide} determine the significance
level and sidedness of the test. By default one-sided testing at level
$\alpha=0.025$ is performed. The sample size allocations are handed
over as a vector via the \code{n} argument (for balanced allocations a
single number is sufficient). Assuming a balanced allocation of 20
patients per dose group, the candidate set \code{mods2} and the doses
from above, the \code{planMM} function can be called as follows

<<>>=
pM <- planMM(mods2, doses, n = 20, alpha = 0.05, twoSide = FALSE, scal = 1.2)
pM
@ 

The first part of the output shows the optimal contrast coefficients
for the different models. The representation of the optimal contrast
is unique as we imposed the condition of unit Euclidean length. In the
output we then obtain the multiplicity adjusted critical value for the
maximum contrast and finally the correlations of the contrasts. In
this example some contrasts are quite highly correlated. For example,
the correlation between \code{emax2} and \code{logistic1} is
\code{0.956}, indicating that both describe similar dose-response
shapes, as can also be seen in Figure~\ref{fig:plotModels}. The beta
model contrast however, seems to be relatively different from the
others. This is due to the fact that the beta model shape is, contrary
to the other model shapes, not monotone. The contrasts can also be
graphically displayed using the \code{plot} method for \code{planMM}
objects (see Figure \ref{fig:planMM}).

\begin{figure}[h!]
 \centering
<<>>=
plot(pM)
@ 
<<fig=true, width=8, height=6, echo = false>>=
print(plot(pM))
@
 \caption{Graphical display of optimal contrasts.}
 \label{fig:planMM}
\end{figure}
\newpage
\subsubsection[Function powerMM]{Function \code{powerMM}}

The \code{powerMM} function is designed to calculate the power to
detect the model shapes in the candidate set for different sample
sizes. We need to hand over either an object of class
\code{fullMod} or the doses, the baseline and the maximum effect
via \code{doses}, \code{base} and \code{maxEff} and the standard
deviation of the response via \code{sigma}. One can calculate the
power for sample sizes ranging from \code{lower} to \code{upper}
in stepsizes \code{step}. Summary functions can be used to
combine the different power values for the different model shapes
into one value, as described in Section~\ref{sec:mcpmodmeth}. By
default the minimum, the mean and the maximum power are
calculated. The resulting power values are returned as an object
of class \code{powerMM} in a matrix. There exists also a
\code{plot} method to display the results graphically. Using the
information packaged in the \code{fmods2} object from above one
obtains the following result

\begin{figure}[h!]
 \centering
<<results = hide>>=
pM <- powerMM(fmods2, sigma = 1, alpha = 0.05, lower = 10, upper = 110, 
            step = 10)
plot(pM, line.at = 0.9, models = "none")
@
<<fig=true, width=8, height=6, echo = false>>=
print(plot(pM, line.at = 0.9, models = "none"))
@
 \caption{Power to detect PoC under the assumed candidate set for different summary functions.}
 \label{fig:power}
\end{figure} 

In Figure \ref{fig:power} it can be seen that a mean power of 90
$\%$ is achieved with approximately 90 patients per dose. Note
that the power can also be calculated for unbalanced but fixed
allocations. The allocation ratios (or allocation weights,
depending on the value of the \code{typeN} argument) then need to
be supplied via the \code{alRatio} argument. In the plot above
only the summary power values are displayed, although the
\code{plot} method for \code{powerMM} allows the display of the
power values for the individual candidate models as well.

\newpage
\subsubsection[Function sampSize]{Function \code{sampSize}}

The \code{sampSize} function calculates the necessary sample size 
to achieve a pre-specified \textit{combined} power value. As input 
parameters we need a \code{fullMod} object (or manually 
\code{doses}, \code{base}, \code{maxEff}) and \code{sigma}. 
Together with the candidate set, these parameters form the 
`alternatives' for which the power is calculated. A summary 
function (via \code{sumFct}) to combine the individual power 
values into one value and the power level we want to achieve (via 
\code{power}) need to be provided as well. For the bisection 
search algorithm an upper bound for the target sample size (via 
\code{upperN}) needs to be provided as a starting value. The 
starting value for the lower bound needed for the bisection is 
derived internally as \code{upperN/2}, but can also be handed over 
manually via \code{lowerN}. When the starting values for the 
upper and lower bound do not bracket a solution the bounds are 
extended automatically. For the information packaged in the 
\code{fmods2} object the result is as follows

<<>>=
sampSize(fmods2, sigma = 1, sumFct = mean, power = 0.9, alpha = 0.05,
       twoSide = FALSE, upperN = 100)
@

As seen from the output, the \code{sampSize} function returns the
desired group sample size and the associated combined power. In
our example we thus need 92 patients per group to guarantee a
mean power of $90\%$. The \code{sampSize} function also returns
the individual power values under the different models in the
candidate set. Note that in the example above we assumed a
balanced sample size allocation. Fixed allocation
proportions can be specified via the \code{alRatio} argument. If
\code{typeN = "arm"}, the code assumes that allocation
\textit{ratios} are passed to \code{alRatio}, which means that
the bisection search algorithm varies the sample size $n_{min}$
in the dose group with the fewest number of patients, and returns
the smallest $n_{min}$ such that the combined power is larger
than \code{power}. If \code{typeN = "total"} allocation
\textit{weights} are assumed and the overall sample size $N$ is
iterated.
\newpage
\subsubsection[Function LP]{Function \code{LP}}

The \code{LP} function is designed to calculate the loss in power
associated with misspecification of the guesstimates for one model in
the candidate set. To illustrate the function we use a very simple
candidate set consisting of only a linear and an E$_{\max}$ shape and
illustrate the calculation of $LP_1$ (see equation~(\ref{eq:lp1})). We
select $0.15$ as the guesstimate for the $ED_{50}$ parameter, and want
to investigate the loss in power in the interval $[0.03,0.8]$
(specified via \code{paramRange}). Hence we calculate how much power
we loose, if an alternative $ED_{50}$ value is true, but we selected
$0.15$ as our guesstimate. As before \code{doses}, \code{base},
\code{maxEff} (or an object of class \code{fullMod}) and \code{sigma}
need to be specified together with the sample size. After calling the
\code{LP} function we display the results using the associated
\code{plot} method. The optional \code{spldf} argument determines the
degrees of freedom for the spline that is used to smooth the power
values in the plot.

\begin{figure}[h!]
 \centering
<<results = hide>>=
mods3 <- list(linear = NULL, emax = 0.15)
Lfit <- LP(mods3, model = "emax", type = "LP1", paramRange = c(0.03, 0.8),
         len = 30, doses = doses, n = 92, base = 0, maxEff = 0.4, 
         sigma = 1, alpha = 0.05, twoSide = FALSE)
plot(Lfit, spldf = 25)
@
<<fig=true, width=8, height=6, echo = false>>=
print(plot(Lfit, spldf = 25))
@
 \caption{Difference of actual and nominal power for Emax model.}
 \label{fig:plotLP}
\end{figure}

As seen from Figure~\ref{fig:plotLP} the loss in power is
relatively large if a small $ED_{50}$ value is true. If the true
$ED_{50}$ is equal to the guesstimate then the actual power and
nominal power coincide. For $ED_{50}$ larger than the specified
guesstimate we actually gain power, because the $E_{\max}$ model
becomes almost linear and is captured by the linear model
included in the candidate set.

\newpage
\subsection{Analysis Code}

The analysis functionalities are incorporated in one main
function \code{MCPMod}, which implements the full MCP-Mod
approach. According to the methodology described in Section 2, it
consists of two main steps: (i) MCP-step (calculation of optimal
contrasts, critical value, contrast test statistics and possibly
$p-$values and selection of the set of significant models) and (ii)
modeling step (model fitting, model selection/model averaging and
dose estimation).

We now describe some of the more important arguments for the
\code{MCPMod} function. For a complete description of the
\code{MCPMod} function we refer to the online documentation. The
dose-response data set is handed over to the \code{MCPMod} function
via the \code{data} argument. It should be handed over as a \code{data
  frame} containing two columns corresponding to the dose levels and
the response values. The \code{selModel} argument determines how
to select a dose estimation model out of the set of significant
models (if there are any significant models). One can choose
between the maximum contrast test statistic (the default option),
the AIC, the BIC or model averaging based on either the AIC or 
the BIC (see Section \ref{sec:mcpmodmeth}). Another important 
argument is \code{doseEst}, which determines the dose estimator 
to be used. Three slightly different estimators for the $MED$ are 
currently implemented (see \cite{bret:pinh:bran:2005} for a 
detailed description of those three estimators, option 
\code{"MED2"} is the default value, corresponding to the 
estimator described in Section \ref{sec:mcpmodmeth}) as well as 
an estimator of the $EDp$. Additional parameters for the dose 
estimators (such as $\gamma$ for $MED$ estimators (default: 
$\gamma=0.1$) and $p$ for the $ED$ estimator (default: $p=0.5$)) 
are handed over via the \code{dePar} argument.  The clinical 
relevance threshold $\Delta$ is handed over via the 
\code{clinRel} argument. The \code{pVal} argument determines, 
whether multiplicity adjusted $p-$values for the multiple 
contrast test should be calculated or not (per default p-values 
are not calculated).

To illustrate the \code{MCPMod} function we use the dose-response 
data set \code{biom} used by \cite{bret:pinh:bran:2005} to 
illustrate the MCP-Mod methodology. The data result from a 
randomized double-blind parallel group trial with a total of 100 
patients being allocated to either placebo or one of four active 
doses coded as 0.05, 0.20, 0.60, and 1, with $20$ patients per 
group. Here, we use the \code{MED2} estimator with $\gamma = 
0.05$ to estimate the $MED$, the clinical threshold $\Delta$ is 
set to 0.4 and the dose estimation model is selected according to 
the maximum contrast test statistic. Employing the candidate 
model set \code{mods2} the results can be obtained by calling

<<>>=
data(biom)
dfe <- MCPMod(biom, mods2, alpha = 0.05, dePar = 0.05, pVal = TRUE,
            selModel = "maxT", doseEst = "MED2", clinRel = 0.4, scal = 1.2)
@

A brief summary of the results is available via the \code{print} method for \code{MCPMod}
objects

<<>>=
dfe
@

From the output we conclude that the maximum contrast is
significant at one-sided level 0.05. Thus a significant
dose-response relationship can be established, \textit{i.e.},
positive PoC. Furthermore we conclude that \code{emax2} has the
largest test statistic among all contrasts and consequently the
E$_{\max}$ model was used for the dose-estimation step. The $MED$
estimate is $0.17$. The $90\%$ in the $MED$ estimate refers to
the confidence level of $L(d)$ used in the dose estimator (see
Section \ref{sec:mcpmodmeth}). A more detailed summary of the
results is available via the \code{summary} method.

<<>>=
summary(dfe)
@

The summary output includes some information about important
input parameters that were used when calling \code{MCPMod}. Then
the output includes also the optimal contrasts and the contrast
correlations together with the contrast test statistics, the
multiplicity adjusted $p-$values and the critical value. Finally,
information about the fitted dose-response model, its parameter
estimates and the target dose estimate are displayed.

A graphical display of the dose-response model used for dose
estimation can be obtained via the \code{plot} method for
\code{MCPMod} objects. When \code{complData = TRUE}, the full
dose-response data set is plotted instead of only the group
means. The \code{clinRel} option determines whether the clinical
relevance threshold should be displayed.

\begin{figure}[h!]
 \centering
<<results = hide>>=
plot(dfe, complData = TRUE, clinRel = TRUE)
@
<<fig=true, width=8, height=6, echo = false>>=
print(plot(dfe, complData = TRUE, clinRel = TRUE))
@
 \caption{Fitted model with data set.}
 \label{fig:MCPMod1}
\end{figure}

To illustrate the different options available for the
\code{MCPMod} function we will now re-analyze the \code{biom}
data set with different input parameters. Specifically, we will
now apply model averaging techniques. The target dose is hence
estimated as the weighted average of the dose estimates under the
different significant models. The weights are determined via the
AIC criterion (see equation~(\ref{eq:buckland})) with uniform
prior weights (which is the default). The target dose we are now
interested in is the $ED95$, which is the dose that achieves 95
$\%$ percent of the maximum effect.

<<>>=
dfe2 <- MCPMod(biom, mods2, alpha = 0.05, dePar = 0.95,
             selModel = "aveAIC", doseEst = "ED", scal = 1.2)
dfe2
@

The output of the \code{print} method now contains the four models
selected for dose-response estimation as well as the model
averaged $ED95$ estimate. We edited the output of the summary
method here as there is some overlap with the previous call to
the \code{summary} function.

<<>>=
summary(dfe2)
@

In addition to the results already described in the
\code{summary(dfe)} call, the output now also contains
information about the AIC of the different models and the model
weights. All model fits are given and the $ED95$ estimate
obtained for all models, as well as the model weighted average of
the dose estimates.

A graphical display of the fitted model functions can be obtained
via the \code{plot} method, here we just plot the model means but
also include the estimated ED95 in the plot.

\begin{figure}[h!]
 \centering
<<results = hide>>=
plot(dfe2, doseEst = TRUE)
@
<<fig=true, width=8, height=7, echo = false>>=
print(plot(dfe2, doseEst = TRUE))
@
 \caption{Fitted models with data set.}
 \label{fig:MCPMod2}
\end{figure}

\section{Summary and Outlook} In this vignette we have 
reviewed the MCP-Mod methodology including its most recent 
developments and described the \pkg{MCPMod} package. Future versions 
will, among other 
features, include bootstrap methods for calculating confidence 
intervals on target dose estimates and the fitted model function, 
inclusions of covariates as well as a version of the 
Golub-Pereyra algorithm, which allows for box constraints.

\bibliography{MCPMod}

\end{document}
